{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Transliteration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gJ84QlEg0PPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b48888c5-96b4-4693-c4c2-70bc5a98bca5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D8ko0FsS0aFp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85e8c323-8939-4e8a-ecfa-1bbc7388358d"
      },
      "source": [
        "device_gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JV0UH-nZ0qRb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "490b5003-c2dd-4aa1-b72d-8ba61c8c4272"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ME3nsMEz0qUB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2013abac-dcca-4c45-e9a6-4a267ff309f8"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mvM19Pdv0qW6",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9_Gy3VWB0qZe",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GyRfTiDR0qcp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "42c6a653-8718-4674-f08e-48109b85154b"
      },
      "source": [
        "train_data = TransliterationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TransliterationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping:  BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping:  DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping:  CAPE TOWN  -  केपटाउन\n",
            "Skipping:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping:  RAMCOIND  -  राम्को इंड\n",
            "Skipping:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping:  JAHAN AARA  -  जहाँआरा\n",
            "Skipping:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping:  OPENTV  -  ओपन टीवी\n",
            "Skipping:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping:  MAUNA LOA  -  मौनालोआ\n",
            "Skipping:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping:  RETALIX  -  रेटालिक्स लि.\n",
            "Skipping:  SRISAILAM  -  श्री शैलम\n",
            "Skipping:  KARA-KUM  -  काराकुम\n",
            "Skipping:  WIND RIVER  -  विंडरिवर\n",
            "Skipping:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z64KbFVb0qgB",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TgmrZNz519dC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "c83b12b2-3bf6-4ba3-f342-3ddbd5abded0"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "hindi_rep = word_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_rep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "गीता tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tSM5fD0A2AdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "55bb109f-02a4-48df-e714-88d2a5d41b07"
      },
      "source": [
        "eng_gt = gt_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_gt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GITA tensor([[ 7],\n",
            "        [ 9],\n",
            "        [20],\n",
            "        [ 1],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9jeCZ-ad2dQZ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9TLcuG9Z2dS7",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hytc4F6g2dXa",
        "colab": {}
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(hindi_alpha2index), 256, len(eng_alpha2index), verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yx660NMT2dbw",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        gt = gt_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        input = word_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NBo1Bi1-pCMo",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J8230zsk2dfk",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model_final.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jgQftM-e2daz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "d8101607-a013-4d78-cbdd-c78c7ee0dc33"
      },
      "source": [
        "loss_history = train_setup(net_attn, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.09552234411239624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E4eODmtp2dWQ",
        "colab": {}
      },
      "source": [
        "gt = gt_rep(eng, eng_alpha2index, device_gpu)\n",
        "input = word_rep(\"ज्योतिष\", hindi_alpha2index, device_gpu)\n",
        "outputs = net_attn(input, 30, device_gpu)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bn7mkoYJu8px",
        "colab": {}
      },
      "source": [
        "op = []\n",
        "\n",
        "for index, output in enumerate(outputs):\n",
        "  values, indices = output[0].max(0)\n",
        "  op.append(indices)\n",
        "\n",
        "#print(char(op))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Ao8xoGhu8sq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "90eae4e5-d058-48ae-dd87-24d9a0d6c540"
      },
      "source": [
        "op2 = []\n",
        "\n",
        "for index, output in enumerate(outputs):\n",
        "  values, indices = output[0].max(0)\n",
        "  op2.append(indices)\n",
        "\n",
        "print(op2)\n",
        "for i in op2:\n",
        "  if(int(i) == 0):\n",
        "    break\n",
        "  print(chr(int(i) + ord('a') - 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(10, device='cuda:0'), tensor(25, device='cuda:0'), tensor(15, device='cuda:0'), tensor(20, device='cuda:0'), tensor(9, device='cuda:0'), tensor(19, device='cuda:0'), tensor(8, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0'), tensor(0, device='cuda:0')]\n",
            "j\n",
            "y\n",
            "o\n",
            "t\n",
            "i\n",
            "s\n",
            "h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2sNOlyxzu0z2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hz8DVGs6u0wO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q7GVg55KuuDS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33b1dad2-554c-4782-ae2e-bb3211e233d4"
      },
      "source": [
        "outputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-12.9989,  -8.3081, -11.1823,  -3.3631, -10.4328, -11.4883, -12.4081,\n",
              "          -14.5248, -13.3009, -12.3960,  -9.3801,  -0.0496,  -9.8191, -11.0619,\n",
              "          -11.2931, -12.2935,  -9.5202,  -4.3726, -15.2638, -11.0886, -10.9095,\n",
              "          -12.3631, -14.3542, -13.9349,  -7.5507, -14.2342, -11.9257]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-1.0866e+01, -1.5523e-02, -1.1677e+01, -8.0915e+00, -1.1752e+01,\n",
              "          -7.5965e+00, -1.5586e+01, -1.5622e+01, -6.8468e+00, -7.9101e+00,\n",
              "          -1.2982e+01, -5.9758e+00, -9.8656e+00, -1.0710e+01, -1.1734e+01,\n",
              "          -5.1281e+00, -1.2742e+01, -8.3143e+00, -1.2204e+01, -1.1323e+01,\n",
              "          -1.2465e+01, -5.4647e+00, -1.6776e+01, -1.3001e+01, -1.1829e+01,\n",
              "          -9.6408e+00, -1.5031e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[ -7.6430,  -1.0112,  -7.3586, -10.4205,  -8.1534,  -8.0425, -13.8338,\n",
              "          -13.2144,  -6.4402,  -6.2000, -13.9748,  -8.8829,  -6.8154,  -0.4885,\n",
              "           -7.1770,  -7.2858, -10.1054, -11.7988,  -7.0640,  -8.0107, -10.0871,\n",
              "           -4.4092, -15.4686, -11.7029, -12.0444,  -6.8025, -13.4701]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[ -5.5662,  -5.3716,  -8.9175,  -9.5196,  -7.9384,  -1.6234,  -9.8996,\n",
              "          -10.3264,  -8.0964,  -0.3301,  -9.6013,  -8.2923,  -7.4857,  -2.7765,\n",
              "           -6.5857, -11.8285,  -8.4660, -10.7068,  -5.5617,  -7.8963, -10.6738,\n",
              "           -8.5046, -11.7684, -13.1444, -11.3094,  -5.2526, -10.2226]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.3876,  -8.1249, -10.1811,  -9.4462,  -7.3380,  -2.1813,  -7.5586,\n",
              "           -9.2152,  -6.3281,  -1.9646,  -9.0490,  -8.2079,  -7.5765,  -7.6252,\n",
              "           -7.3677, -10.3335, -10.5558,  -9.7623,  -6.5860,  -8.1611,  -9.5574,\n",
              "           -9.7246, -10.6336, -11.6805, -10.4314,  -2.8020,  -9.5652]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.1357,  -8.1550, -11.3237, -10.1596,  -9.3516,  -2.3352,  -9.0911,\n",
              "          -10.4178,  -6.4755,  -3.9620, -12.0550,  -8.9240,  -8.7881,  -8.4829,\n",
              "           -9.2426, -11.6364, -10.9981, -11.3499,  -7.9909,  -8.6912,  -9.9655,\n",
              "           -9.9785, -11.9732, -12.5952, -11.5379,  -4.8677, -12.0031]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0655,  -8.6329, -12.7852, -10.8507, -10.8547,  -2.9672, -10.0190,\n",
              "          -11.9166,  -6.8897,  -4.9562, -13.8868,  -9.4259,  -9.6377,  -9.4851,\n",
              "          -10.2345, -12.7213, -12.1980, -12.5658,  -8.8203,  -9.8204, -10.6528,\n",
              "          -10.9857, -13.2563, -13.8409, -12.8417,  -5.7621, -13.8652]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0352,  -9.0180, -13.3048, -11.1853, -11.5338,  -3.5859, -10.6000,\n",
              "          -12.6741,  -7.2231,  -5.5779, -14.4796,  -9.6072, -10.1091,  -9.8215,\n",
              "          -10.6358, -13.3620, -12.8131, -13.1343,  -9.3375, -10.4127, -11.1491,\n",
              "          -11.6757, -13.8984, -14.5588, -13.4988,  -6.2990, -14.7370]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0237,  -9.2743, -13.4771, -11.3398, -11.7880,  -4.0010, -10.9115,\n",
              "          -13.0371,  -7.3234,  -5.9260, -14.6363,  -9.6440, -10.3470,  -9.9080,\n",
              "          -10.8065, -13.7375, -13.1404, -13.4467,  -9.6376, -10.6260, -11.4462,\n",
              "          -12.0671, -14.2899, -15.0371, -13.8446,  -6.6077, -15.1300]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[ -0.0183,  -9.4319, -13.5978, -11.4451, -11.9451,  -4.2785, -11.1063,\n",
              "          -13.2623,  -7.3432,  -6.1536, -14.7120,  -9.6752, -10.5086,  -9.9710,\n",
              "          -10.9180, -13.9589, -13.3470, -13.6819,  -9.8225, -10.7195, -11.6300,\n",
              "          -12.3134, -14.5799, -15.3710, -14.0922,  -6.8197, -15.3653]],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-1.5138e-02, -9.5426e+00, -1.3695e+01, -1.1526e+01, -1.2074e+01,\n",
              "          -4.4814e+00, -1.1244e+01, -1.3420e+01, -7.3478e+00, -6.3191e+00,\n",
              "          -1.4766e+01, -9.7122e+00, -1.0627e+01, -1.0025e+01, -1.0999e+01,\n",
              "          -1.4098e+01, -1.3485e+01, -1.3870e+01, -9.9558e+00, -1.0767e+01,\n",
              "          -1.1756e+01, -1.2485e+01, -1.4799e+01, -1.5605e+01, -1.4283e+01,\n",
              "          -6.9841e+00, -1.5522e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-1.3135e-02, -9.6258e+00, -1.3773e+01, -1.1588e+01, -1.2182e+01,\n",
              "          -4.6362e+00, -1.1350e+01, -1.3539e+01, -7.3532e+00, -6.4450e+00,\n",
              "          -1.4808e+01, -9.7450e+00, -1.0713e+01, -1.0069e+01, -1.1060e+01,\n",
              "          -1.4195e+01, -1.3581e+01, -1.4023e+01, -1.0058e+01, -1.0789e+01,\n",
              "          -1.1845e+01, -1.2616e+01, -1.4967e+01, -1.5778e+01, -1.4432e+01,\n",
              "          -7.1133e+00, -1.5632e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-1.1744e-02, -9.6907e+00, -1.3837e+01, -1.1635e+01, -1.2275e+01,\n",
              "          -4.7593e+00, -1.1438e+01, -1.3634e+01, -7.3602e+00, -6.5448e+00,\n",
              "          -1.4842e+01, -9.7694e+00, -1.0779e+01, -1.0106e+01, -1.1110e+01,\n",
              "          -1.4268e+01, -1.3652e+01, -1.4147e+01, -1.0138e+01, -1.0794e+01,\n",
              "          -1.1910e+01, -1.2721e+01, -1.5103e+01, -1.5912e+01, -1.4551e+01,\n",
              "          -7.2162e+00, -1.5714e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-1.0716e-02, -9.7426e+00, -1.3890e+01, -1.1671e+01, -1.2356e+01,\n",
              "          -4.8609e+00, -1.1514e+01, -1.3712e+01, -7.3677e+00, -6.6265e+00,\n",
              "          -1.4868e+01, -9.7857e+00, -1.0832e+01, -1.0139e+01, -1.1152e+01,\n",
              "          -1.4327e+01, -1.3707e+01, -1.4250e+01, -1.0204e+01, -1.0789e+01,\n",
              "          -1.1957e+01, -1.2808e+01, -1.5216e+01, -1.6021e+01, -1.4649e+01,\n",
              "          -7.3005e+00, -1.5779e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-9.9214e-03, -9.7847e+00, -1.3935e+01, -1.1696e+01, -1.2429e+01,\n",
              "          -4.9470e+00, -1.1581e+01, -1.3779e+01, -7.3748e+00, -6.6950e+00,\n",
              "          -1.4889e+01, -9.7954e+00, -1.0874e+01, -1.0168e+01, -1.1191e+01,\n",
              "          -1.4375e+01, -1.3752e+01, -1.4336e+01, -1.0260e+01, -1.0779e+01,\n",
              "          -1.1994e+01, -1.2883e+01, -1.5312e+01, -1.6112e+01, -1.4730e+01,\n",
              "          -7.3715e+00, -1.5832e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-9.2857e-03, -9.8195e+00, -1.3972e+01, -1.1714e+01, -1.2495e+01,\n",
              "          -5.0216e+00, -1.1641e+01, -1.3837e+01, -7.3812e+00, -6.7536e+00,\n",
              "          -1.4905e+01, -9.8003e+00, -1.0909e+01, -1.0192e+01, -1.1226e+01,\n",
              "          -1.4417e+01, -1.3788e+01, -1.4409e+01, -1.0309e+01, -1.0764e+01,\n",
              "          -1.2023e+01, -1.2948e+01, -1.5397e+01, -1.6189e+01, -1.4800e+01,\n",
              "          -7.4329e+00, -1.5876e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-8.7647e-03, -9.8483e+00, -1.4004e+01, -1.1727e+01, -1.2555e+01,\n",
              "          -5.0871e+00, -1.1694e+01, -1.3888e+01, -7.3869e+00, -6.8045e+00,\n",
              "          -1.4918e+01, -9.8014e+00, -1.0937e+01, -1.0214e+01, -1.1258e+01,\n",
              "          -1.4454e+01, -1.3817e+01, -1.4471e+01, -1.0352e+01, -1.0748e+01,\n",
              "          -1.2048e+01, -1.3006e+01, -1.5472e+01, -1.6255e+01, -1.4859e+01,\n",
              "          -7.4868e+00, -1.5914e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-8.3300e-03, -9.8723e+00, -1.4030e+01, -1.1734e+01, -1.2610e+01,\n",
              "          -5.1452e+00, -1.1742e+01, -1.3934e+01, -7.3919e+00, -6.8492e+00,\n",
              "          -1.4928e+01, -9.7999e+00, -1.0960e+01, -1.0232e+01, -1.1289e+01,\n",
              "          -1.4486e+01, -1.3842e+01, -1.4525e+01, -1.0391e+01, -1.0730e+01,\n",
              "          -1.2069e+01, -1.3057e+01, -1.5538e+01, -1.6313e+01, -1.4911e+01,\n",
              "          -7.5347e+00, -1.5947e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-7.9618e-03, -9.8924e+00, -1.4053e+01, -1.1739e+01, -1.2659e+01,\n",
              "          -5.1972e+00, -1.1785e+01, -1.3975e+01, -7.3963e+00, -6.8891e+00,\n",
              "          -1.4936e+01, -9.7964e+00, -1.0978e+01, -1.0247e+01, -1.1317e+01,\n",
              "          -1.4514e+01, -1.3862e+01, -1.4571e+01, -1.0427e+01, -1.0713e+01,\n",
              "          -1.2088e+01, -1.3103e+01, -1.5599e+01, -1.6364e+01, -1.4956e+01,\n",
              "          -7.5775e+00, -1.5976e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-7.6463e-03, -9.9091e+00, -1.4072e+01, -1.1741e+01, -1.2705e+01,\n",
              "          -5.2439e+00, -1.1824e+01, -1.4012e+01, -7.4002e+00, -6.9249e+00,\n",
              "          -1.4942e+01, -9.7914e+00, -1.0993e+01, -1.0261e+01, -1.1344e+01,\n",
              "          -1.4539e+01, -1.3880e+01, -1.4611e+01, -1.0460e+01, -1.0695e+01,\n",
              "          -1.2105e+01, -1.3145e+01, -1.5653e+01, -1.6409e+01, -1.4996e+01,\n",
              "          -7.6160e+00, -1.6002e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-7.3731e-03, -9.9232e+00, -1.4088e+01, -1.1740e+01, -1.2746e+01,\n",
              "          -5.2862e+00, -1.1859e+01, -1.4046e+01, -7.4035e+00, -6.9573e+00,\n",
              "          -1.4947e+01, -9.7855e+00, -1.1005e+01, -1.0272e+01, -1.1370e+01,\n",
              "          -1.4561e+01, -1.3894e+01, -1.4647e+01, -1.0490e+01, -1.0678e+01,\n",
              "          -1.2120e+01, -1.3182e+01, -1.5704e+01, -1.6450e+01, -1.5031e+01,\n",
              "          -7.6508e+00, -1.6026e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-7.1349e-03, -9.9349e+00, -1.4101e+01, -1.1738e+01, -1.2785e+01,\n",
              "          -5.3245e+00, -1.1891e+01, -1.4077e+01, -7.4064e+00, -6.9869e+00,\n",
              "          -1.4951e+01, -9.7789e+00, -1.1014e+01, -1.0281e+01, -1.1394e+01,\n",
              "          -1.4581e+01, -1.3907e+01, -1.4678e+01, -1.0518e+01, -1.0661e+01,\n",
              "          -1.2134e+01, -1.3216e+01, -1.5750e+01, -1.6486e+01, -1.5062e+01,\n",
              "          -7.6823e+00, -1.6047e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-6.9255e-03, -9.9447e+00, -1.4113e+01, -1.1734e+01, -1.2820e+01,\n",
              "          -5.3595e+00, -1.1920e+01, -1.4106e+01, -7.4089e+00, -7.0141e+00,\n",
              "          -1.4955e+01, -9.7719e+00, -1.1021e+01, -1.0289e+01, -1.1417e+01,\n",
              "          -1.4598e+01, -1.3917e+01, -1.4705e+01, -1.0544e+01, -1.0644e+01,\n",
              "          -1.2147e+01, -1.3248e+01, -1.5793e+01, -1.6519e+01, -1.5090e+01,\n",
              "          -7.7109e+00, -1.6067e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-6.7400e-03, -9.9529e+00, -1.4123e+01, -1.1729e+01, -1.2852e+01,\n",
              "          -5.3915e+00, -1.1947e+01, -1.4132e+01, -7.4110e+00, -7.0391e+00,\n",
              "          -1.4958e+01, -9.7646e+00, -1.1026e+01, -1.0295e+01, -1.1439e+01,\n",
              "          -1.4614e+01, -1.3927e+01, -1.4730e+01, -1.0568e+01, -1.0629e+01,\n",
              "          -1.2159e+01, -1.3277e+01, -1.5832e+01, -1.6548e+01, -1.5115e+01,\n",
              "          -7.7368e+00, -1.6085e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-6.5747e-03, -9.9598e+00, -1.4131e+01, -1.1723e+01, -1.2881e+01,\n",
              "          -5.4208e+00, -1.1972e+01, -1.4157e+01, -7.4128e+00, -7.0624e+00,\n",
              "          -1.4961e+01, -9.7573e+00, -1.1031e+01, -1.0301e+01, -1.1460e+01,\n",
              "          -1.4629e+01, -1.3934e+01, -1.4752e+01, -1.0591e+01, -1.0614e+01,\n",
              "          -1.2171e+01, -1.3303e+01, -1.5869e+01, -1.6575e+01, -1.5137e+01,\n",
              "          -7.7604e+00, -1.6103e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-6.4267e-03, -9.9655e+00, -1.4138e+01, -1.1717e+01, -1.2909e+01,\n",
              "          -5.4479e+00, -1.1994e+01, -1.4180e+01, -7.4142e+00, -7.0840e+00,\n",
              "          -1.4964e+01, -9.7499e+00, -1.1033e+01, -1.0305e+01, -1.1481e+01,\n",
              "          -1.4641e+01, -1.3941e+01, -1.4771e+01, -1.0612e+01, -1.0600e+01,\n",
              "          -1.2182e+01, -1.3327e+01, -1.5904e+01, -1.6599e+01, -1.5157e+01,\n",
              "          -7.7820e+00, -1.6119e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-6.2934e-03, -9.9702e+00, -1.4145e+01, -1.1710e+01, -1.2934e+01,\n",
              "          -5.4728e+00, -1.2015e+01, -1.4201e+01, -7.4154e+00, -7.1042e+00,\n",
              "          -1.4966e+01, -9.7426e+00, -1.1035e+01, -1.0309e+01, -1.1500e+01,\n",
              "          -1.4653e+01, -1.3947e+01, -1.4789e+01, -1.0632e+01, -1.0586e+01,\n",
              "          -1.2192e+01, -1.3350e+01, -1.5937e+01, -1.6622e+01, -1.5176e+01,\n",
              "          -7.8017e+00, -1.6134e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-6.1729e-03, -9.9741e+00, -1.4150e+01, -1.1703e+01, -1.2958e+01,\n",
              "          -5.4960e+00, -1.2034e+01, -1.4220e+01, -7.4164e+00, -7.1231e+00,\n",
              "          -1.4969e+01, -9.7355e+00, -1.1037e+01, -1.0312e+01, -1.1519e+01,\n",
              "          -1.4663e+01, -1.3952e+01, -1.4806e+01, -1.0650e+01, -1.0574e+01,\n",
              "          -1.2201e+01, -1.3371e+01, -1.5968e+01, -1.6642e+01, -1.5193e+01,\n",
              "          -7.8198e+00, -1.6148e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-6.0632e-03, -9.9774e+00, -1.4155e+01, -1.1695e+01, -1.2979e+01,\n",
              "          -5.5175e+00, -1.2052e+01, -1.4239e+01, -7.4171e+00, -7.1409e+00,\n",
              "          -1.4972e+01, -9.7286e+00, -1.1037e+01, -1.0314e+01, -1.1537e+01,\n",
              "          -1.4673e+01, -1.3957e+01, -1.4821e+01, -1.0667e+01, -1.0561e+01,\n",
              "          -1.2210e+01, -1.3391e+01, -1.5997e+01, -1.6661e+01, -1.5208e+01,\n",
              "          -7.8363e+00, -1.6161e+01]], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([[-5.9632e-03, -9.9801e+00, -1.4160e+01, -1.1687e+01, -1.3000e+01,\n",
              "          -5.5376e+00, -1.2068e+01, -1.4256e+01, -7.4176e+00, -7.1576e+00,\n",
              "          -1.4974e+01, -9.7220e+00, -1.1037e+01, -1.0316e+01, -1.1555e+01,\n",
              "          -1.4681e+01, -1.3961e+01, -1.4835e+01, -1.0683e+01, -1.0550e+01,\n",
              "          -1.2219e+01, -1.3410e+01, -1.6025e+01, -1.6679e+01, -1.5223e+01,\n",
              "          -7.8515e+00, -1.6174e+01]], device='cuda:0', grad_fn=<ViewBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g4ym7vDbn2uG",
        "colab": {}
      },
      "source": [
        "net_attn(input, 30, device_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15z4kVHDOm9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}